{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de43a602-df9f-42a8-8899-a53b0bb48fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9773b39-5f52-43f5-8b45-c144232875f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Metadata...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print('Loading Metadata...')\n",
    "data_folder = 'data/PsychAD_freeze2_personalized_grpahs/'\n",
    "meta = pd.read_csv(data_folder + 'syn26527784_latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79154959-5b27-40db-a6ac-a4849a6380c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "# Defaultdict with depth\n",
    "def deepdefaultdict(depth, default=None):\n",
    "    if depth == 0:\n",
    "        return None\n",
    "    return defaultdict(lambda: deepdefaultdict(depth-1, default=default))\n",
    "\n",
    "# Prune zero-length array entries from d=1 dict\n",
    "def prunedict(dic):\n",
    "    newdic = {}\n",
    "    for k in dic:\n",
    "        if len(dic[k]) > 0:\n",
    "            newdic[k] = dic[k]\n",
    "    return newdic\n",
    "\n",
    "# Convert to dict\n",
    "def dd2d(dd):\n",
    "    if type(dd) == type(defaultdict()):\n",
    "        for k in dd:\n",
    "            dd[k] = dd2d(dd[k])\n",
    "        return(dict(dd))\n",
    "    return dd\n",
    "\n",
    "# Hyperparameters\n",
    "cell_type_top_regulons = 20\n",
    "edge_percentile = 0\n",
    "edge_present_pct = 99"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2209310-7949-49ec-baba-36013a8faf17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Step-by-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c86b90-96ff-4788-8d16-747c4e19827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "# stratify_cols = ['BRAAK_AD', 'nps_PsychoAgiHxValue']\n",
    "# # Hx - Historical/Ever Seen\n",
    "# # 'BRAAK_AD', 'Sex'\n",
    "# # 'nps_PsychoAgiCurValue', 'nps_PsychoAgiHxValue'\n",
    "# # 'nps_RumCurValue', 'nps_RumHxValue'\n",
    "# # 'nps_PsychoRetardCurValue', 'nps_PsychoRetardHxValue'\n",
    "# # 'nps_FatCurValue', 'nps_FatHxValue'\n",
    "# stratify_cols.sort()\n",
    "# cell_type = 'Mural'  # EN Endo Glial Immune IN Mural None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8dd1b3-5952-430d-b372-3d23ef391a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stratify by column\n",
    "# print('Gathering...')\n",
    "# graph_ids = {}\n",
    "# unique_vals = [np.unique(meta[col].astype(str)) for col in stratify_cols]\n",
    "# for vals in product(*unique_vals):\n",
    "#     print('\\t'.join([f'{col}: {val}' for col, val in zip(stratify_cols, vals)]), end='')\n",
    "#     current_filter = np.array([True for _ in range(meta.shape[0])])\n",
    "#     for col, val in zip(stratify_cols, vals):\n",
    "#         current_filter *= (meta[col].astype(str) == val)\n",
    "#     graph_ids[vals] = list(meta.loc[current_filter]['SubID'])\n",
    "#     print(f'\\t({len(graph_ids[vals])} IDs)')\n",
    "# graph_ids = prunedict(graph_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50bd5755-a024-4f1f-ad3f-0076cc5e8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Aggregate graphs\n",
    "# print('Processing...')\n",
    "# processed_graphs = {}\n",
    "# num_graphs = defaultdict(lambda: 0)\n",
    "# for k, v in graph_ids.items():\n",
    "#     print('\\t'.join([f'{col}: {val}' for col, val in zip(stratify_cols, k)]), end='')\n",
    "#     running_graph = defaultdict(lambda: defaultdict(list))\n",
    "#     for graph_id in v:\n",
    "#         # Load individual graph\n",
    "#         try:\n",
    "#             graph = pd.read_csv(data_folder + f'regulon_grn/{graph_id}_regulon_list.csv')[['TF', 'gene', 'CoexWeight', 'regulon']]\n",
    "#             graph = graph.rename(columns={'gene': 'TG', 'CoexWeight': 'coef'})  # TF, TG, coef, regulon\n",
    "#         except:\n",
    "#             continue\n",
    "#         # Filter to regulons based on cell-type\n",
    "#         if cell_type is not None:\n",
    "#             try:\n",
    "#                 rss = pd.read_csv(data_folder + f'rss/{graph_id}_6_celltype_rss.csv', index_col=0)\n",
    "#                 assert cell_type in rss.index\n",
    "#                 # Top x regulons\n",
    "#                 regulons = rss.loc[cell_type].nlargest(cell_type_top_regulons).index\n",
    "#                 graph = graph.loc[np.isin(np.array(graph['regulon']), regulons)]\n",
    "#             except:\n",
    "#                 continue\n",
    "#             # Top x percent of coefs\n",
    "#             graph = graph.loc[np.array(graph['coef']) > np.percentile(graph['coef'], edge_percentile)]\n",
    "#         graph = graph[['TF', 'TG', 'coef']]\n",
    "#         num_graphs[k] += 1\n",
    "#         for _, row in graph.iterrows():\n",
    "#             tf, tg, coef = row\n",
    "#             running_graph[tf][tg].append(coef)\n",
    "#     print(f'\\t({num_graphs[k]} Graphs)')\n",
    "#     processed_graphs[k] = dd2d(running_graph)\n",
    "# num_graphs = dict(num_graphs)\n",
    "# processed_graphs = prunedict(processed_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138f9211-6f6a-48b0-a438-566bad641a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keep edges which have some references in common\n",
    "# print('Filtering...')\n",
    "# edgelists = {}\n",
    "# for k0, v0 in processed_graphs.items():\n",
    "#     print('\\t'.join([f'{col}: {val}' for col, val in zip(stratify_cols, k0)]), end='')\n",
    "#     # Calculate min edges\n",
    "#     edge_counts = []\n",
    "#     for k1, v1 in v0.items():\n",
    "#         for k2, v2 in v1.items():\n",
    "#             edge_counts.append(len(v2))\n",
    "#     min_edges = np.percentile(edge_counts, edge_present_pct)\n",
    "#     edges = []\n",
    "#     num_edges = 0\n",
    "#     for k1, v1 in v0.items():\n",
    "#         for k2, v2 in v1.items():\n",
    "#             if len(v2) >= min_edges:\n",
    "#                 edges.append([k1, k2, np.mean(v2)])\n",
    "#                 num_edges += 1\n",
    "#     print(f'\\t({num_edges} Edges)')\n",
    "#     edgelists[k0] = edges\n",
    "# edgelists = prunedict(edgelists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4356301d-eb35-4e4e-8125-447046df6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Saving...')\n",
    "# for k in edgelists:\n",
    "#     print('\\t'.join([f'{col}: {val}' for col, val in zip(stratify_cols, k)]))\n",
    "#     pd.DataFrame(edgelists[k], columns=['TF', 'TG', 'coef']).to_csv(\n",
    "#         data_folder\n",
    "#         + f'processed/grn_{f\"{cell_type}_\" if cell_type is not None else \"\"}'\n",
    "#         f'{\"_\".join([f\"{col}_{val}\" for col, val in zip(stratify_cols, k)])}.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55e475cb-8a2f-4923-ac65-ee0785468aba",
   "metadata": {},
   "source": [
    "# Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d8434de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/DiseaseNeuroGenomics/psychad_metadata/blob/main/psychad_clinical_metadata_querying.R\n",
    "diagnosis_classification = {\n",
    "  'neurodegenerative': ['AD', 'MCI', 'Dementia', 'PD', 'PD_uncertain_plus_encephalitic', 'DLBD', 'FTD', 'ALS', 'Others_Neurodegenerative'],\n",
    "  'neurological': ['MS', 'PSP', 'Epilepsy', 'Seizures', 'Tumor', 'Migraine_headaches', 'Head_Injury', 'Vascular', 'Others_Neurological'], \n",
    "  'neuropsychiatric': ['SCZ', 'MDD', 'BD_unspecific', 'BD_I', 'BD_II', 'PTSD', 'ADHD', 'OCD', 'Tardive_Dyskinesia_Neuroleptic_induced', 'Schizoaffective_bipolar', 'Schizoaffective_depressive', 'Anorexia', 'Bulimia', 'Anxiety', 'Binge_Purge', 'Eating_disorder', 'Others_Neuropsychiatric'],\n",
    "  'metabolic': ['Diabetes_mellitus_unspecified', 'TD_I', 'TD_II'],\n",
    "}\n",
    "diagnosis_benign = ['Anxiety', 'Migraine_headaches'] + diagnosis_classification['metabolic']\n",
    "all_dx = [j for i in diagnosis_classification.values() for j in i]  # Different than file\n",
    "deleterious_dx = list(set(all_dx) - set(diagnosis_benign))\n",
    "\n",
    "# Macros\n",
    "MSSM_OVER_60 = lambda x: (\n",
    "    (x['Age'].astype(int) >= 60)\n",
    "    * (x['Brain_bank'].astype(str) == 'MSSM'))\n",
    "RUSH_OVER_60 = lambda x: (\n",
    "    (x['Age'].astype(int) >= 60)\n",
    "    * (x['Brain_bank'].astype(str) == 'RUSH'))\n",
    "MSSM = lambda x: (x['Brain_bank'].astype(str) == 'MSSM')\n",
    "HBCC = lambda x: (x['Brain_bank'].astype(str) == 'HBCC')\n",
    "\n",
    "# Disease\n",
    "AD = lambda x: (\n",
    "    (x.fillna(0)[list(set(deleterious_dx) - set(['MCI', 'Dementia', 'AD']))].sum(axis=1) == 0)\n",
    "    * (x['AD'].fillna(-1).astype(int) == 1))\n",
    "AD_STRICT = lambda x: (\n",
    "    (x.fillna(0)[list(set(deleterious_dx) - set(['MCI', 'Dementia', 'AD']))].sum(axis=1) == 0)\n",
    "    * (x['CERAD'].fillna(-1).astype(int).isin([4]))\n",
    "    * (x['BRAAK_AD'].fillna(-1).astype(int).isin([3, 4, 5, 6]))\n",
    "    * (x['Dementia'].fillna(-1).astype(int) == 1)\n",
    "    * (x['Brain_bank'].astype(str) != 'HBCC'))\n",
    "SCZ = lambda x: (\n",
    "    (x.fillna(0)[list(set(deleterious_dx) - set(['SCZ', 'Schizoaffective_bipolar', 'Schizoaffective_depressive', 'Dementia', 'MCI']))].sum(axis=1) == 0)\n",
    "    * (x.fillna(0)[['SCZ', 'Schizoaffective_bipolar', 'Schizoaffective_depressive']].sum(axis=1) > 0))\n",
    "\n",
    "# Control (Missing metadata)\n",
    "CONTROLS_NEUROPATHOLOGICAL_CLINICAL = lambda x: (\n",
    "    (x.fillna(0)[list(set(deleterious_dx) - set(['MCI', 'Dementia', 'AD']))].sum(axis=1) == 0)\n",
    "    * (\n",
    "        (x['CERAD'].fillna(-1).astype(int).isin([1, 2]))\n",
    "        * (x['BRAAK_AD'].fillna(-1).astype(int).isin([0, 1, 2]))\n",
    "        + (x['Brain_bank'].astype(str) == 'HBCC')\n",
    "    ))\n",
    "CONTROLS_SUPERCONTROLS = lambda x: (\n",
    "    (x.fillna(0)[list(set(deleterious_dx) - set(['AD']))].sum(axis=1) == 0)\n",
    "    * (\n",
    "        (x['CERAD'].fillna(-1).astype(int).isin([1]))\n",
    "        * (x['BRAAK_AD'].fillna(-1).astype(int).isin([0, 1, 2]))\n",
    "        + (x['Brain_bank'].astype(str) == 'HBCC')\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4de8ee0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c01x:\t257 283\n",
      "c02x:\t455 395\n",
      "c03x:\t68 395\n",
      "c06x:\t463 140\n",
      "c11x:\t523 395\n",
      "strict_vs_lenient:\t303 531\n"
     ]
    }
   ],
   "source": [
    "# CELLS\n",
    "# EN Endo Glial Immune IN Mural None\n",
    "cell_type_list = ['EN', 'Endo', 'Glial', 'Immune', 'IN', 'Mural', None]\n",
    "\n",
    "# STRATIFY COLUMNS\n",
    "stratify_cols_list = [\n",
    "    ['nps_PsychoAgiCurValue'],\n",
    "    ['HippoPlaquesValue'],\n",
    "    ['AmygPlaquesValue'],\n",
    "    ['HippoPlaquesWCoresValue'],\n",
    "    ['AmygTanglesValue'],\n",
    "    ['OcciPlaquesValue'],\n",
    "    ['OcciPlaquesWCoresValue'],\n",
    "]\n",
    "\n",
    "# FILTERS\n",
    "contrast_list = {\n",
    "    'c01x': [lambda x: MSSM_OVER_60(x) * AD_STRICT(x), lambda x: CONTROLS_SUPERCONTROLS(x)],\n",
    "    'c02x': [lambda x: MSSM_OVER_60(x) * AD(x), lambda x: CONTROLS_NEUROPATHOLOGICAL_CLINICAL(x)],\n",
    "    'c03x': [lambda x: RUSH_OVER_60(x) * AD(x), lambda x: CONTROLS_NEUROPATHOLOGICAL_CLINICAL(x)],\n",
    "    'c06x': [lambda x: (MSSM(x) + HBCC(x)) * AD(x), lambda x: (MSSM(x) + HBCC(x)) * SCZ(x)],\n",
    "    'c11x': [lambda x: (MSSM_OVER_60(x) + RUSH_OVER_60(x)) * AD(x), lambda x: CONTROLS_NEUROPATHOLOGICAL_CLINICAL(x)],\n",
    "    'strict_vs_lenient': [lambda x: AD_STRICT(x), lambda x: AD(x)],\n",
    "}\n",
    "contrast_titles = {\n",
    "    'c01x': ['StrictAD', 'SuperControl'],\n",
    "    'c02x': ['AD', 'Control'],\n",
    "    'c03x': ['AD', 'Control'],\n",
    "    'c06x': ['AD', 'SCZ'],\n",
    "    'c11x': ['AD', 'Control'],\n",
    "    'strict_vs_lenient': ['StrictAD', 'AD'],\n",
    "}\n",
    "for k, v in contrast_list.items():\n",
    "    print(f'{k}:\\t{sum(v[0](meta))} {sum(v[1](meta))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a11ead-98e1-4efb-bf76-1f9b85065c29",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/294 [02:04<2:57:28, 36.59s/it]"
     ]
    }
   ],
   "source": [
    "for cell_type, stratify_cols, contrast_name in tqdm(product(cell_type_list, stratify_cols_list, contrast_list), total=len(cell_type_list)*len(stratify_cols_list)*len(contrast_list)):\n",
    "    # print(cell_type)\n",
    "    # print(stratify_cols)\n",
    "    # print(filter_name)\n",
    "    \n",
    "    # Stratify by column\n",
    "    # print('Gathering...')\n",
    "    graph_ids = {}\n",
    "    unique_vals = [np.unique(meta[col].astype(str)) for col in stratify_cols]\n",
    "\n",
    "    # Add contrast to stratify\n",
    "    if contrast_name:\n",
    "        stratify_cols = stratify_cols + [contrast_name]\n",
    "        unique_vals = unique_vals + [contrast_titles[contrast_name]]\n",
    "\n",
    "    for vals in product(*unique_vals):\n",
    "        # Isolate contrast\n",
    "        if contrast_name:\n",
    "            iter_stratify = zip(stratify_cols[:-1], vals[:-1])\n",
    "        else:\n",
    "            iter_stratify = zip(stratify_cols, vals)\n",
    "\n",
    "        # Stratify column\n",
    "        # print('\\t'.join([f'{col}: {val}' for col, val in zip(stratify_cols, vals)]), end='')\n",
    "        current_filter = np.array([True for _ in range(meta.shape[0])])\n",
    "        for col, val in iter_stratify:\n",
    "            current_filter *= (meta[col].astype(str) == val)\n",
    "        \n",
    "        # Contrasts\n",
    "        if contrast_name:\n",
    "            current_filter *= contrast_list[contrast_name][np.argwhere(np.array(contrast_titles[contrast_name]) == vals[-1])[0][0]](meta)\n",
    "\n",
    "        graph_ids[vals] = list(meta.loc[current_filter]['SubID'])\n",
    "        # print(f'\\t({len(graph_ids[vals])} IDs)')\n",
    "    graph_ids = prunedict(graph_ids)\n",
    "\n",
    "    # Aggregate graphs\n",
    "    # print('Processing...')\n",
    "    processed_graphs = {}\n",
    "    num_graphs = defaultdict(lambda: 0)\n",
    "    for k, v in graph_ids.items():\n",
    "        # print('\\t'.join([f'{col}: {val}' for col, val in zip(stratify_cols, k)]), end='')\n",
    "        running_graph = defaultdict(lambda: defaultdict(list))\n",
    "        for graph_id in v:\n",
    "            # Load individual graph\n",
    "            try:\n",
    "                graph = pd.read_csv(data_folder + f'regulon_grn/{graph_id}_regulon_list.csv')[['TF', 'gene', 'CoexWeight', 'regulon']]\n",
    "                graph = graph.rename(columns={'gene': 'TG', 'CoexWeight': 'coef'})  # TF, TG, coef, regulon\n",
    "            except:\n",
    "                continue\n",
    "            # Filter to regulons based on cell-type\n",
    "            if cell_type is not None:\n",
    "                try:\n",
    "                    rss = pd.read_csv(data_folder + f'rss/{graph_id}_6_celltype_rss.csv', index_col=0)\n",
    "                    assert cell_type in rss.index\n",
    "                    # Top x regulons\n",
    "                    regulons = rss.loc[cell_type].nlargest(cell_type_top_regulons).index\n",
    "                    graph = graph.loc[np.isin(np.array(graph['regulon']), regulons)]\n",
    "                except:\n",
    "                    continue\n",
    "                # Top x percent of coefs\n",
    "                graph = graph.loc[np.array(graph['coef']) > np.percentile(graph['coef'], edge_percentile)]\n",
    "            graph = graph[['TF', 'TG', 'coef']]\n",
    "            num_graphs[k] += 1\n",
    "            for _, row in graph.iterrows():\n",
    "                tf, tg, coef = row\n",
    "                running_graph[tf][tg].append(coef)\n",
    "        # print(f'\\t({num_graphs[k]} Graphs)')\n",
    "        processed_graphs[k] = dd2d(running_graph)\n",
    "    num_graphs = dict(num_graphs)\n",
    "    processed_graphs = prunedict(processed_graphs)\n",
    "\n",
    "    # Keep edges which have some references in common\n",
    "    # print('Filtering...')\n",
    "    edgelists = {}\n",
    "    for k0, v0 in processed_graphs.items():\n",
    "        # print('\\t'.join([f'{col}: {val}' for col, val in zip(stratify_cols, k0)]), end='')\n",
    "        # Calculate min edges\n",
    "        edge_counts = []\n",
    "        for k1, v1 in v0.items():\n",
    "            for k2, v2 in v1.items():\n",
    "                edge_counts.append(len(v2))\n",
    "        min_edges = np.percentile(edge_counts, edge_present_pct)\n",
    "        edges = []\n",
    "        num_edges = 0\n",
    "        for k1, v1 in v0.items():\n",
    "            for k2, v2 in v1.items():\n",
    "                if len(v2) >= min_edges:\n",
    "                    edges.append([k1, k2, np.mean(v2)])\n",
    "                    num_edges += 1\n",
    "        # print(f'\\t({num_edges} Edges)')\n",
    "        edgelists[k0] = edges\n",
    "    edgelists = prunedict(edgelists)\n",
    "\n",
    "    # print('Saving...')\n",
    "    for k in edgelists:\n",
    "        # print('\\t'.join([f'{col}: {val}' for col, val in zip(stratify_cols, k)]))\n",
    "        pd.DataFrame(edgelists[k], columns=['TF', 'TG', 'coef']).to_csv(\n",
    "            data_folder\n",
    "            + f'processed/grn_{f\"{cell_type}_\" if cell_type is not None else \"\"}'\n",
    "            f'{\"_\".join([f\"{col}_{val}\" for col, val in zip(stratify_cols, k)])}.csv')\n",
    "    \n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2bad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
