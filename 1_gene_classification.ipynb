{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b0ac0f1-9a18-4e03-954a-4d272c3b5d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import operator\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pecanpy as pp\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import auc, confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as tg\n",
    "import torch_geometric.nn as gnn\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf09fd0-82f3-47db-ba43-d15575e20e39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "style='white'\n",
    "sns.set(style=style)\n",
    "plt.rcParams.update({'font.weight': 'normal',\n",
    "                     'font.size': 18,\n",
    "                     'axes.titlesize': 'large',\n",
    "                     'axes.labelsize': 'large',\n",
    "                     'xtick.labelsize': 'small',\n",
    "                     'ytick.labelsize': 'small'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ef79f8-b4a5-4d01-99dc-02af8d518084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "directed = True\n",
    "disease_type = 'AD'  # Either 'disease' or 'graph-labels' e.g. 'AD', 'AD-SCZ'\n",
    "def create_dirs(dirs):\n",
    "    for d in dirs:\n",
    "        if not os.path.exists(d):\n",
    "            os.mkdir(d)\n",
    "def get_dirs(disease_type):\n",
    "    model_dir = f'./models/{disease_type}'\n",
    "    results_dir = f'./results/{disease_type}'\n",
    "    output = (model_dir, results_dir)\n",
    "    create_dirs(output)\n",
    "    return output\n",
    "model_dir, results_dir = get_dirs(disease_type)\n",
    "\n",
    "# Run params\n",
    "runs = 20  # Number of runs\n",
    "folds = 5  # Folds per run\n",
    "run, fold = 0, 0  # Current stat\n",
    "percentile = 80  # Data filtering\n",
    "# RW params\n",
    "param_grid = {\n",
    "    'dim': [16, 32, 64, 128, 248, 512],\n",
    "    'num_walks': [20, 40, 60, 80, 100],\n",
    "    'walk_length': [10],\n",
    "    'dropout': [0, .4, .6, .8],\n",
    "    'gamma': [.96, .99, .995],\n",
    "    'lr': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "}\n",
    "np.random.seed(42)\n",
    "dim_list = np.random.choice(param_grid['dim'], runs)\n",
    "num_walks_list = np.random.choice(param_grid['num_walks'], runs)\n",
    "walk_length_list = np.random.choice(param_grid['walk_length'], runs)\n",
    "dropout_list = np.random.choice(param_grid['dropout'], runs)\n",
    "gamma_list = np.random.choice(param_grid['gamma'], runs)\n",
    "lr_list = np.random.choice(param_grid['lr'], runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0143b74-a2c8-493b-83a6-8a684b8d8ab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec6dd93-7f51-4788-bf5d-69895399ec23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Astrocyte\n",
      "Endothelial\n",
      "GABAergic neuron\n",
      "GABAergic PVALB interneuron\n",
      "GABAergic SST interneuron\n",
      "GABAergic VIP interneuron\n",
      "Glutamatergic neuron\n",
      "Microglia\n",
      "Mural\n",
      "Oligodendrocyte\n",
      "OPC\n"
     ]
    }
   ],
   "source": [
    "def get_cells(disease_type, directed=False):\n",
    "    cell_fnames = np.array([s for s in os.listdir(f'./data/psychAD_merged_GRN_0.2_0.2/{disease_type.split(\"-\")[0]}') if s[0] != '_'])\n",
    "    cell_types = [ct.split('.')[0] for ct in cell_fnames]\n",
    "    cell_fname = cell_fnames[0]\n",
    "    cell_type = cell_fname.split('.')[0]\n",
    "    \n",
    "    return (cell_fnames, cell_types), (cell_fname, cell_type)\n",
    "\n",
    "(cell_fnames, cell_types), (cell_fname, cell_type) = get_cells(disease_type, directed=directed)\n",
    "for ct in cell_types:\n",
    "    print(ct) if ct != cell_type else print(f'--{ct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46e4613c-a6f0-4596-bd91-04a635309a21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Astrocyte graph...\n",
      "Filtering data...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_data(cell_fname, method='scGRNom', directed=True, output='_elist.edg'):  # 'scGRNom', 'SCENIC'\n",
    "    # Read data\n",
    "    tftg = pd.read_csv(f'./data/psychAD_merged_GRN_0.2_0.2/{disease_type.split(\"-\")[0]}/{cell_fname}', sep='\\t', low_memory=False)  # low_memory avoids loading warning\n",
    "    # Control data\n",
    "    is_pec2 = (cell_fname.split('.')[1] == 'PEC2')\n",
    "    coef_col = 'edgeWeight' if not is_pec2 else 'coef'\n",
    "    # Filter to one method (SCENIC, scGRNom)\n",
    "    if method is not None and not is_pec2:\n",
    "        tftg = tftg.iloc[np.argwhere((tftg['method']==method).to_numpy()).flatten(), :]\n",
    "    # Remove all zero weights\n",
    "    tftg = tftg.iloc[np.argwhere(tftg[coef_col].to_numpy() != 0).flatten(), :]\n",
    "    # Remove negatives\n",
    "    tftg = tftg.iloc[np.argwhere(tftg[coef_col].to_numpy() > 0).flatten(), :]\n",
    "    # Set all nonzero weights to one\n",
    "    if method is None and not is_pec2:\n",
    "        tftg[[coef_col]] = 1.\n",
    "    # Filter to targets\n",
    "    tftg = tftg[['TF', 'TG', coef_col]]\n",
    "    # Make undirected\n",
    "    tg_genes = np.unique(tftg['TG'])\n",
    "    if not directed:\n",
    "        tftg = pd.DataFrame(\n",
    "            np.concatenate([tftg[['TF', 'TG', coef_col]].to_numpy(), tftg[['TG', 'TF', coef_col]].to_numpy()]))\n",
    "    # Save file\n",
    "    tftg.to_csv(output, sep='\\t', header=None, index=None)\n",
    "    \n",
    "    return tg_genes\n",
    "\n",
    "def get_labels(genes, disease_type, gene_filter=[]):\n",
    "    # # DisGeNet\n",
    "    # disDict = {'AD': 'Alzheimer', 'SCZ': 'Schizophrenia', 'PK': 'Parkinson', 'BD': 'Bipolar Disorder'}\n",
    "    # meta = pd.read_csv(f'./data/training_labels_disgenet_raw/all_gene_disease_associations.tsv', index_col=None, sep='\\t')\n",
    "    # dis_strs = [s for s in np.unique(meta['diseaseName']) if f'{disDict[disease_type.split(\"-\")[-1]].lower()}' in s.lower() and f'Non-{disDict[disease_type.split(\"-\")[-1]]}'.lower() not in s.lower()]\n",
    "    # filtered_meta = meta.iloc[[np.array([ds==s for ds in dis_strs]).any() for s in meta['diseaseName']]]\n",
    "    # filtered_meta = filtered_meta.sort_values('score', ascending=False)\n",
    "    # filtered_meta = filtered_meta.iloc[:int(.1 * filtered_meta.shape[0])]  # TODO, more fine-tuning\n",
    "    # positive_genes = np.array(filtered_meta['geneSymbol'])\n",
    "    \n",
    "    # Assoc\n",
    "    positive_genes = pd.read_csv(f'./data/new_labels/{disease_type.split(\"-\")[-1]}.txt', index_col=None, header=None).to_numpy().flatten()\n",
    "    \n",
    "    # Get labels\n",
    "    labels = np.array([('pos' if (g in positive_genes) else 'neg') if (g in gene_filter) else 'unk' for g in genes])  # TODO, better method than unknown being neg\n",
    "    return labels\n",
    "\n",
    "def filter_elist(percentile):\n",
    "    elist = pd.read_csv('_elist.edg', sep='\\t', header=None)\n",
    "\n",
    "    # Eliminate low-value data\n",
    "    reg_threshold = np.percentile(elist.iloc[:, 2].to_numpy().flatten(), percentile)\n",
    "    elist = elist.iloc[np.argwhere((elist.iloc[:, 2] >= reg_threshold).to_numpy()).flatten(), :]\n",
    "    elist.to_csv('_elist.edg', sep='\\t', header=None, index=None)\n",
    "    \n",
    "    return reg_threshold\n",
    "\n",
    "print(f'Generating {cell_type} graph...')\n",
    "# Load data\n",
    "tg_genes = get_data(cell_fname, directed=directed)\n",
    "\n",
    "# Plot approximate distribution\n",
    "elist = pd.read_csv('_elist.edg', sep='\\t', header=None)\n",
    "sns.displot(elist.iloc[:, 2].to_numpy().flatten(), log_scale=True)\n",
    "\n",
    "# Eliminate low-value data\n",
    "print(f'Filtering data...')\n",
    "reg_threshold = filter_elist(percentile)\n",
    "plt.axvline(reg_threshold, ymax=.1, color='black');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a320aadd-e0e1-4ac1-bc7a-bc688da2754d",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb00a4d-7325-4561-b0c9-460402e2b756",
   "metadata": {},
   "source": [
    "## Node2Vec+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a40a4027-6f59-405c-baa5-e0541df39b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading graph...\n",
      "Loading embeddings...\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings_from_elist(model_dir, cell_type, tg_genes, dim, num_walks, walk_length, percentile, run, verbose=False, return_g=False):\n",
    "    if verbose:\n",
    "        print('Reading graph...')\n",
    "    # Load as precomp\n",
    "    g = pp.pecanpy.SparseOTF(p=1, q=1, workers=4, verbose=False, random_state=42+run)\n",
    "    g.read_edg('_elist.edg', weighted=True, directed=directed)\n",
    "    # g.preprocess_transition_probs()\n",
    "\n",
    "    fname = f'{model_dir}/embeddings-{cell_type}-{run}.npy'\n",
    "    if os.path.exists(fname):\n",
    "        if verbose:\n",
    "            print('Loading embeddings...')\n",
    "        # Load embeddings\n",
    "        emb_pp = np.load(fname)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('Generating embeddings...')\n",
    "        # Generate embeddings\n",
    "        emb_pp = g.embed(dim=dim, num_walks=num_walks, walk_length=walk_length)\n",
    "        np.save(fname, emb_pp)\n",
    "        hparams = np.array([\n",
    "            ['percentile', 'dim', 'num_walks', 'walk_length'],\n",
    "            [percentile, dim, num_walks, walk_length],\n",
    "        ])\n",
    "        np.savetxt(fname[:-4]+'.txt', hparams, fmt=' '.join(hparams.shape[1]*['%s']))\n",
    "\n",
    "    # Chart connected subgraph\n",
    "    # surviving_nodes = [np.argwhere(genes==gn).flatten()[0] for gn in g.nodes]\n",
    "    genes = np.array(g.nodes)\n",
    "    labels = get_labels(genes, disease_type, gene_filter=tg_genes)\n",
    "    \n",
    "    output = (genes, labels, emb_pp)\n",
    "    if return_g:\n",
    "        return output, g\n",
    "    return output\n",
    "\n",
    "dim, num_walks, walk_length = dim_list[run], num_walks_list[run], walk_length_list[run]\n",
    "genes, labels, emb_pp = get_embeddings_from_elist(model_dir, cell_type, tg_genes, dim, num_walks, walk_length, percentile, run, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1f2677-407a-46f3-93eb-e300ea3aeecf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 4\n",
      "Mean: 1.15\n",
      "Median: 1.0\n",
      "{1: 188200, 2: 32384, 3: 701, 4: 15}\n"
     ]
    }
   ],
   "source": [
    "# Additional Graph Information\n",
    "_, g = get_embeddings_from_elist(model_dir, cell_type, tg_genes, dim, num_walks, walk_length, percentile, run, verbose=False, return_g=True)\n",
    "walks = g.simulate_walks(num_walks, walk_length)\n",
    "walk_lengths = np.array([len(walk) for walk in walks])\n",
    "walk_length_counts = {u: c for u, c in zip(*np.unique(walk_lengths, return_counts=True))}\n",
    "print(f'Max: {walk_lengths.max()}\\nMean: {walk_lengths.mean():.2f}\\nMedian: {np.median(walk_lengths):.1f}\\n{walk_length_counts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd56eb-6917-4251-acd5-1d42dbc2080d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dbd4d1f-18a0-482b-be5c-fead48fa9339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2213, 128], edge_index=[2, 48336], y=[2213], edge_weight=[48336], train_mask=[2213], val_mask=[2213], unk_mask=[2213])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_dataset(genes, labels, emb_pp, fold, folds, run):\n",
    "    # Load dataset\n",
    "    elist = np.loadtxt('_elist.edg', dtype=str)\n",
    "    gene_to_index = {g: i for g, i in zip(genes, range(len(genes)))}\n",
    "    edge_index = np.array([[gene_to_index[f] for f in e[:2]] for e in elist]).T\n",
    "    edge_weight = np.array([float(e[2]) for e in elist])\n",
    "\n",
    "    # Add embeddings and labels\n",
    "    x = emb_pp\n",
    "    y = np.array([{'pos': 1, 'neg': 0, 'unk': 2}[l] for l in labels])\n",
    "\n",
    "    # Split data\n",
    "    np.random.seed(42 + run)\n",
    "    unk_idx = np.argwhere(y==2).flatten()\n",
    "    unk_mask = np.zeros(x.shape[0], dtype=bool)\n",
    "    unk_mask[unk_idx] = True\n",
    "    groups = np.random.choice(folds, x.shape[0])\n",
    "    train_idx = np.argwhere(groups!=fold).flatten()\n",
    "    train_idx = np.array(list(set(train_idx) - set(unk_idx)))\n",
    "    train_mask = np.zeros(x.shape[0], dtype=bool)\n",
    "    train_mask[train_idx] = True\n",
    "    val_idx = np.array(list(set(list(range(x.shape[0]))) - set(train_idx)))\n",
    "    val_idx = np.array(list(set(val_idx) - set(unk_idx)))\n",
    "    val_mask = np.zeros(x.shape[0], dtype=bool)\n",
    "    val_mask[val_idx] = True\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = tg.data.Data(\n",
    "        x=torch.tensor(x).float(),\n",
    "        edge_index=torch.tensor(edge_index, dtype=int),\n",
    "        edge_weight=torch.tensor(edge_weight).float(),\n",
    "        y=torch.tensor(y, dtype=int),\n",
    "        train_mask=torch.tensor(train_mask),\n",
    "        val_mask=torch.tensor(val_mask),\n",
    "        unk_mask=torch.tensor(unk_mask))\n",
    "    assert dataset.is_directed() == directed\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = generate_dataset(genes, labels, emb_pp, fold, folds, run)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c2471-1daf-4f4d-bc28-07c68233eaf1",
   "metadata": {},
   "source": [
    "## Model Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afee8144-39a9-4f2a-b91f-c4852eca9c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class GCN(torch.nn.Module):\n",
    "#     def __init__(self, input_size, **kwargs):\n",
    "#         super().__init__()\n",
    "#         self.encode = gnn.Sequential('x, edge_index, edge_weight', [\n",
    "#             (nn.Linear(input_size, 2*input_size), 'x -> x'),\n",
    "#             # (gnn.GCNConv(32, 64), 'x, edge_index, edge_weight -> x'),\n",
    "#             # (nn.LeakyReLU(), 'x -> x'),\n",
    "#             (gnn.GCNConv(2*input_size, input_size), 'x, edge_index, edge_weight -> x'),\n",
    "#             (nn.LeakyReLU(), 'x -> x'),\n",
    "#             (gnn.GCNConv(input_size, int(input_size/2)), 'x, edge_index, edge_weight -> x'),\n",
    "#             (nn.LeakyReLU(), 'x -> x'),\n",
    "#         ])\n",
    "#         self.decode = gnn.Sequential('x, edge_index, edge_weight', [\n",
    "#             (nn.Linear(int(input_size/2), 2), 'x -> x'),\n",
    "#             # (gnn.GCNConv(16, 2), 'x, edge_index, edge_weight -> x'),\n",
    "#             (nn.LogSoftmax(dim=-1), 'x -> x'),\n",
    "#         ])\n",
    "\n",
    "#     def forward(self, data):\n",
    "#         x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weight\n",
    "#         return self.decode(self.encode(x, edge_index, edge_weight), edge_index, edge_weight)\n",
    "\n",
    "# model_str = 'gcn'\n",
    "# model_class = GCN\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, dropout=.6, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encode = nn.Sequential(\n",
    "            # nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(input_size, 2*input_size),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.BatchNorm1d(2*input_size),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Linear(2*input_size, input_size),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Linear(input_size, int(input_size/2)),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.BatchNorm1d(int(input_size/2)),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(int(input_size/2), 2),\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weight\n",
    "        return self.decode(self.encode(x))\n",
    "    \n",
    "model_str = 'mlp'\n",
    "model_class = MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b28f2-7c05-4cc9-9420-d737a812e859",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494c4eac-cdb8-4c55-82aa-cb94bb8c5a2f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_model(model_class, dataset, model_dir, model_str, cell_type, dim, num_walks, walk_length, dropout, lr, gamma, percentile, fold, folds, run, verbose=False, return_epoch=False):\n",
    "    torch.manual_seed(42 + run*folds + fold)\n",
    "    np.random.seed(42 + run*folds + fold)\n",
    "\n",
    "    # Train model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model_class(dataset.x.shape[1], dropout=dropout).to(device)\n",
    "    data = dataset.to(device)\n",
    "    # Optim with lr decay\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=gamma)\n",
    "\n",
    "    fname = f'{model_dir}/{model_str}-{cell_type}-{run}-{fold}_{folds}.h5'\n",
    "    hp_fname = f'{model_dir}/{model_str}-{cell_type}-{run}.txt'\n",
    "    model.train()\n",
    "    if os.path.exists(fname):\n",
    "        epoch = 0\n",
    "        model.load_state_dict(torch.load(fname))\n",
    "    else:\n",
    "        max_lapses = 100; min_improvement = 1e-2  # 500, 50\n",
    "        min_loss = np.inf; lapses = 0\n",
    "        for epoch in range(10_001):\n",
    "            # Step\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Use validation loss\n",
    "            val_loss = F.nll_loss(out[data.val_mask], data.y[data.val_mask])\n",
    "            use_loss = val_loss\n",
    "            \n",
    "            # CLI\n",
    "            if use_loss < min_loss - min_improvement:\n",
    "                min_loss = use_loss.detach()\n",
    "                lapses = 0\n",
    "            else:\n",
    "                lapses += 1\n",
    "            if lapses >= max_lapses:\n",
    "                if verbose:\n",
    "                    print(f'Epoch {epoch}\\nTrain Loss: {float(loss.detach()):.4f}\\nValid Loss: {float(val_loss.detach()):.4f}')\n",
    "                break\n",
    "            if epoch % 100 == 0:\n",
    "                # val_loss = F.nll_loss(out[data.val_mask], data.y[data.val_mask])\n",
    "                if verbose:\n",
    "                    print(f'Epoch {epoch}\\nTrain Loss: {float(loss.detach()):.4f}\\nValid Loss: {float(val_loss.detach()):.4f}')\n",
    "        torch.save(model.state_dict(), fname)\n",
    "        hparams = np.array([\n",
    "            ['percentile', 'dim', 'num_walks', 'walk_length', 'dropout', 'lr', 'gamma'],\n",
    "            [percentile, dim, num_walks, walk_length, dropout, lr, gamma],\n",
    "        ])\n",
    "        np.savetxt(hp_fname, hparams, fmt=' '.join(hparams.shape[1]*['%s']))\n",
    "    model.eval()\n",
    "    \n",
    "    if return_epoch:\n",
    "        return model, epoch\n",
    "    return model\n",
    "\n",
    "\n",
    "dropout, lr, gamma = dropout_list[run], lr_list[run], gamma_list[run]\n",
    "model = generate_model(model_class, dataset, model_dir, model_str, cell_type, dim, num_walks, walk_length, dropout, lr, gamma, percentile, fold, folds, run, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a09445a-cd7f-4e0f-b035-41a5abf7949c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:\t0.5414\n"
     ]
    }
   ],
   "source": [
    "def evaluate_predictions(model, dataset, labels):\n",
    "    pred_raw = model(dataset).detach()\n",
    "    pred = pred_raw.argmax(dim=1)\n",
    "    threshold = pred_raw[dataset.train_mask, 1].flatten().quantile(1 - (sum(labels=='pos') / (sum(labels=='pos') + sum(labels=='neg'))))\n",
    "    logits = pred_raw[:, 1][dataset.val_mask]\n",
    "    trans = {'pos': 1, 'neg': 0, 'unk': 2}\n",
    "    trans_inv = {v: k for k, v in trans.items()}\n",
    "    true = torch.Tensor([trans[l] for l in labels[dataset.val_mask]]).long()\n",
    "\n",
    "    # AUROC\n",
    "    fpr, tpr, thresholds = roc_curve(true[np.argwhere(true!=2).squeeze()], logits[np.argwhere(true!=2).squeeze()])\n",
    "    auroc = auc(fpr, tpr)\n",
    "\n",
    "    return auroc, pred_raw\n",
    "\n",
    "auroc, pred_raw = evaluate_predictions(model, dataset, labels)\n",
    "print(f'AUROC:\\t{auroc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e0af8-4bb7-4b66-b0f5-5189e0446225",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Advanced Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b304653-58f4-46cc-88be-591af1776f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred_raw = model(dataset.to(device)).detach()\n",
    "# pred = pred_raw.argmax(dim=1)\n",
    "# threshold = pred_raw[data.train_mask, 1].flatten().quantile(1 - (sum(labels=='pos') / (sum(labels=='pos') + sum(labels=='neg'))))\n",
    "\n",
    "# print('Evaluating performance...')\n",
    "# print('Train')\n",
    "# ## Train\n",
    "# # Perform prediction\n",
    "# logits = pred_raw[:, 1][data.train_mask]\n",
    "# trans = {'pos': 1, 'neg': 0, 'unk': 2}\n",
    "# trans_inv = {v: k for k, v in trans.items()}\n",
    "# true = torch.Tensor([trans[l] for l in labels[dataset.train_mask]]).long()\n",
    "\n",
    "# # Get confusion\n",
    "# conf = confusion_matrix(true, 1*(logits > threshold))\n",
    "# # conf = confusion_matrix(true, pred)\n",
    "# print('T\\P\\t' + '\\t'.join([trans_inv[i] for i in range(len(trans_inv)-1)]))\n",
    "# for i, row in enumerate(conf):\n",
    "#     print(trans_inv[i] + '\\t' + '\\t'.join([str(e) for e in row]))\n",
    "\n",
    "# # Other statistics\n",
    "# fpr, tpr, thresholds = roc_curve(true[np.argwhere(true!=2).squeeze()], logits[np.argwhere(true!=2).squeeze()])\n",
    "# print(f'AUROC:\\t{auc(fpr, tpr):.4f}')\n",
    "# prec, rec, thresholds = precision_recall_curve(true[np.argwhere(true!=2).squeeze()], logits[np.argwhere(true!=2).squeeze()])\n",
    "# print(f'AUPRC:\\t{auc(rec, prec):.4f}')\n",
    "# correct = (pred[data.train_mask] == data.y[dataset.train_mask]).sum()\n",
    "# acc = int(correct) / int(dataset.train_mask.sum())\n",
    "# print(f'Accuracy: {acc:.4f}')\n",
    "# print()\n",
    "\n",
    "# print('Eval')\n",
    "# ## Eval\n",
    "# # Perform prediction\n",
    "# logits = pred_raw[:, 1][data.val_mask]\n",
    "# trans = {'pos': 1, 'neg': 0, 'unk': 2}\n",
    "# trans_inv = {v: k for k, v in trans.items()}\n",
    "# true = torch.Tensor([trans[l] for l in labels[dataset.val_mask]]).long()\n",
    "\n",
    "# # Get confusion\n",
    "# conf = confusion_matrix(true, 1*(logits > threshold))\n",
    "# # conf = confusion_matrix(true, pred)\n",
    "# print('T\\P\\t' + '\\t'.join([trans_inv[i] for i in range(len(trans_inv))]))\n",
    "# for i, row in enumerate(conf):\n",
    "#     print(trans_inv[i] + '\\t' + '\\t'.join([str(e) for e in row]))\n",
    "\n",
    "# # Other statistics\n",
    "# fpr, tpr, thresholds = roc_curve(true[np.argwhere(true!=2).squeeze()], logits[np.argwhere(true!=2).squeeze()])\n",
    "# print(f'AUROC:\\t{auc(fpr, tpr):.4f}')\n",
    "# prec, rec, thresholds = precision_recall_curve(true[np.argwhere(true!=2).squeeze()], logits[np.argwhere(true!=2).squeeze()])\n",
    "# print(f'AUPRC:\\t{auc(rec, prec):.4f}')\n",
    "# correct = (pred[dataset.val_mask] == dataset.y[dataset.val_mask]).sum()\n",
    "# acc = int(correct) / int(dataset.val_mask.sum())\n",
    "# print(f'Accuracy: {acc:.4f}')\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504dae6f-2edf-4119-9ee2-2fb1bbd0eebd",
   "metadata": {},
   "source": [
    "## Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717831e-0aec-45e6-a38a-88ca9f2d7ee5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Astrocyte\n",
      "------Run 1\n",
      "---Fold 1\tAUROC:\t0.5414\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4432\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.6545\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3664\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5503\tEpochs:\t0\n",
      "------Run 2\n",
      "---Fold 1\tAUROC:\t0.6806\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5968\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4296\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4495\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4912\tEpochs:\t0\n",
      "------Run 3\n",
      "---Fold 1\tAUROC:\t0.5597\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4616\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5245\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4515\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.7225\tEpochs:\t0\n",
      "------Run 4\n",
      "---Fold 1\tAUROC:\t0.4510\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.3838\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.6785\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4722\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5814\tEpochs:\t0\n",
      "------Run 5\n",
      "---Fold 1\tAUROC:\t0.5058\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5677\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5279\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4751\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4699\tEpochs:\t0\n",
      "------Run 6\n",
      "---Fold 1\tAUROC:\t0.6530\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.3765\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4510\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4424\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5194\tEpochs:\t0\n",
      "------Run 7\n",
      "---Fold 1\tAUROC:\t0.4688\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4048\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4014\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3340\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4940\tEpochs:\t0\n",
      "------Run 8\n",
      "---Fold 1\tAUROC:\t0.5363\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5504\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4505\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5872\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3764\tEpochs:\t0\n",
      "------Run 9\n",
      "---Fold 1\tAUROC:\t0.5866\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5323\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5391\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4914\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4693\tEpochs:\t0\n",
      "------Run 10\n",
      "---Fold 1\tAUROC:\t0.5887\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.3281\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4099\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4465\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5327\tEpochs:\t0\n",
      "------Run 11\n",
      "---Fold 1\tAUROC:\t0.4432\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4653\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5615\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5822\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5698\tEpochs:\t0\n",
      "------Run 12\n",
      "---Fold 1\tAUROC:\t0.5627\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5036\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5571\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6739\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4999\tEpochs:\t0\n",
      "------Run 13\n",
      "---Fold 1\tAUROC:\t0.5871\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5244\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4069\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5315\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5752\tEpochs:\t0\n",
      "------Run 14\n",
      "---Fold 1\tAUROC:\t0.6203\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5851\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4440\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4425\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4814\tEpochs:\t0\n",
      "------Run 15\n",
      "---Fold 1\tAUROC:\t0.5491\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4063\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.3901\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5280\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3626\tEpochs:\t0\n",
      "------Run 16\n",
      "---Fold 1\tAUROC:\t0.4716\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6604\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4860\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6656\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5799\tEpochs:\t0\n",
      "------Run 17\n",
      "---Fold 1\tAUROC:\t0.3879\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5283\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4385\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5948\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4874\tEpochs:\t0\n",
      "------Run 18\n",
      "---Fold 1\tAUROC:\t0.4761\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5791\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5681\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4631\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5047\tEpochs:\t0\n",
      "------Run 19\n",
      "---Fold 1\tAUROC:\t0.4401\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4859\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5300\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5917\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4443\tEpochs:\t0\n",
      "------Run 20\n",
      "---Fold 1\tAUROC:\t0.4413\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5667\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4506\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4775\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4958\tEpochs:\t0\n",
      "---------Endothelial\n",
      "------Run 1\n",
      "---Fold 1\tAUROC:\t0.4304\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4776\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4374\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5391\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4776\tEpochs:\t0\n",
      "------Run 2\n",
      "---Fold 1\tAUROC:\t0.6484\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5914\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5310\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4609\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5439\tEpochs:\t0\n",
      "------Run 3\n",
      "---Fold 1\tAUROC:\t0.4706\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4042\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.7052\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4433\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3665\tEpochs:\t0\n",
      "------Run 4\n",
      "---Fold 1\tAUROC:\t0.6471\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4124\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.1187\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3825\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.1972\tEpochs:\t0\n",
      "------Run 5\n",
      "---Fold 1\tAUROC:\t0.4445\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4663\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5363\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5729\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4725\tEpochs:\t0\n",
      "------Run 6\n",
      "---Fold 1\tAUROC:\t0.4456\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4655\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.3947\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5391\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3665\tEpochs:\t0\n",
      "------Run 7\n",
      "---Fold 1\tAUROC:\t0.4687\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.7438\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5854\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3357\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.6357\tEpochs:\t0\n",
      "------Run 8\n",
      "---Fold 1\tAUROC:\t0.5510\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5425\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5460\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5668\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5525\tEpochs:\t0\n",
      "------Run 9\n",
      "---Fold 1\tAUROC:\t0.5005\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5059\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.3427\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4826\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5124\tEpochs:\t0\n",
      "------Run 10\n",
      "---Fold 1\tAUROC:\t0.3868\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6104\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5425\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3389\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4642\tEpochs:\t0\n",
      "------Run 11\n",
      "---Fold 1\tAUROC:\t0.6531\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5820\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4735\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.2352\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4266\tEpochs:\t0\n",
      "------Run 12\n",
      "---Fold 1\tAUROC:\t0.5011\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5977\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.6121\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4652\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5572\tEpochs:\t0\n",
      "------Run 13\n",
      "---Fold 1\tAUROC:\t0.5682\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6063\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.6565\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6523\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5781\tEpochs:\t0\n",
      "------Run 14\n",
      "---Fold 1\tAUROC:\t0.2795\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4623\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5629\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3520\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4205\tEpochs:\t0\n",
      "------Run 15\n",
      "---Fold 1\tAUROC:\t0.3740\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4684\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5177\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4960\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5437\tEpochs:\t0\n",
      "------Run 16\n",
      "---Fold 1\tAUROC:\t0.4707\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5315\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.3183\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4516\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4332\tEpochs:\t0\n",
      "------Run 17\n",
      "---Fold 1\tAUROC:\t0.5820\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5618\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4827\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4160\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4875\tEpochs:\t0\n",
      "------Run 18\n",
      "---Fold 1\tAUROC:\t0.3657\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.3863\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.3897\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3989\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5841\tEpochs:\t0\n",
      "------Run 19\n",
      "---Fold 1\tAUROC:\t0.4655\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5273\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5470\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5153\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4931\tEpochs:\t0\n",
      "------Run 20\n",
      "---Fold 1\tAUROC:\t0.5508\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5193\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4685\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4222\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4684\tEpochs:\t0\n",
      "---------GABAergic neuron\n",
      "------Run 1\n",
      "---Fold 1\tAUROC:\t0.5865\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4101\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4115\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4060\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.2949\tEpochs:\t0\n",
      "------Run 2\n",
      "---Fold 1\tAUROC:\t0.6438\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6228\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5897\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.8429\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3839\tEpochs:\t0\n",
      "------Run 3\n",
      "---Fold 1\tAUROC:\t0.6953\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5174\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.6140\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6911\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.6975\tEpochs:\t0\n",
      "------Run 4\n",
      "---Fold 1\tAUROC:\t0.5994\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.3919\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4950\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5933\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5035\tEpochs:\t0\n",
      "------Run 5\n",
      "---Fold 1\tAUROC:\t0.5679\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.3472\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.2753\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4527\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4382\tEpochs:\t0\n",
      "------Run 6\n",
      "---Fold 1\tAUROC:\t0.4206\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4893\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4702\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4892\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3294\tEpochs:\t0\n",
      "------Run 7\n",
      "---Fold 1\tAUROC:\t0.4798\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6951\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5361\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.2635\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5915\tEpochs:\t0\n",
      "------Run 8\n",
      "---Fold 1\tAUROC:\t0.4423\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6734\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4823\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5343\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3430\tEpochs:\t0\n",
      "------Run 9\n",
      "---Fold 1\tAUROC:\t0.5940\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.8159\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4514\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5335\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.6405\tEpochs:\t0\n",
      "------Run 10\n",
      "---Fold 1\tAUROC:\t0.6171\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4712\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4500\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5359\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4936\tEpochs:\t0\n",
      "------Run 11\n",
      "---Fold 1\tAUROC:\t0.5776\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6502\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.6860\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5238\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5432\tEpochs:\t0\n",
      "------Run 12\n",
      "---Fold 1\tAUROC:\t0.5576\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.7207\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5621\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5279\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4446\tEpochs:\t0\n",
      "------Run 13\n",
      "---Fold 1\tAUROC:\t0.5232\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6237\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4560\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5149\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.7142\tEpochs:\t0\n",
      "------Run 14\n",
      "---Fold 1\tAUROC:\t0.5618\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5648\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.2468\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5669\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4500\tEpochs:\t0\n",
      "------Run 15\n",
      "---Fold 1\tAUROC:\t0.4223\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4006\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4654\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6000\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.2117\tEpochs:\t0\n",
      "------Run 16\n",
      "---Fold 1\tAUROC:\t0.5848\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.3119\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4390\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3507\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5162\tEpochs:\t0\n",
      "------Run 17\n",
      "---Fold 1\tAUROC:\t0.5274\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5115\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4873\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4700\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.2349\tEpochs:\t0\n",
      "------Run 18\n",
      "---Fold 1\tAUROC:\t0.4058\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.2660\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.3503\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4070\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4898\tEpochs:\t0\n",
      "------Run 19\n",
      "---Fold 1\tAUROC:\t0.5364\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5404\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4898\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6006\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3993\tEpochs:\t0\n",
      "------Run 20\n",
      "---Fold 1\tAUROC:\t0.5395\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.3847\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.3698\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3628\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.6727\tEpochs:\t0\n",
      "---------GABAergic PVALB interneuron\n",
      "------Run 1\n",
      "---Fold 1\tAUROC:\t0.4174\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4768\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.3554\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4298\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4433\tEpochs:\t0\n",
      "------Run 2\n",
      "---Fold 1\tAUROC:\t0.4877\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5508\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4303\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6116\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.1975\tEpochs:\t0\n",
      "------Run 3\n",
      "---Fold 1\tAUROC:\t0.3476\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4788\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4609\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5955\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4051\tEpochs:\t0\n",
      "------Run 4\n",
      "---Fold 1\tAUROC:\t0.6164\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5143\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.6646\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6730\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5282\tEpochs:\t0\n",
      "------Run 5\n",
      "---Fold 1\tAUROC:\t0.7703\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.7277\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.6124\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.7006\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4731\tEpochs:\t0\n",
      "------Run 6\n",
      "---Fold 1\tAUROC:\t0.5048\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6094\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4216\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5381\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4398\tEpochs:\t0\n",
      "------Run 7\n",
      "---Fold 1\tAUROC:\t0.5604\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.3783\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.6049\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5192\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3312\tEpochs:\t0\n",
      "------Run 8\n",
      "---Fold 1\tAUROC:\t0.5137\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4817\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5077\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.7759\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5301\tEpochs:\t0\n",
      "------Run 9\n",
      "---Fold 1\tAUROC:\t0.5159\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.3100\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.9060\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3850\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.9006\tEpochs:\t0\n",
      "------Run 10\n",
      "---Fold 1\tAUROC:\t0.3585\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4652\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4044\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6310\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3894\tEpochs:\t0\n",
      "------Run 11\n",
      "---Fold 1\tAUROC:\t0.3631\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4330\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5373\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6063\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4655\tEpochs:\t0\n",
      "------Run 12\n",
      "---Fold 1\tAUROC:\t0.3069\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5665\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.3563\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4436\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3960\tEpochs:\t0\n",
      "------Run 13\n",
      "---Fold 1\tAUROC:\t0.4935\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5779\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5165\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5300\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4656\tEpochs:\t0\n",
      "------Run 14\n",
      "---Fold 1\tAUROC:\t0.5192\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5388\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.7829\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.7556\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4586\tEpochs:\t0\n",
      "------Run 15\n",
      "---Fold 1\tAUROC:\t0.6063\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.7082\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4901\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5249\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3063\tEpochs:\t0\n",
      "------Run 16\n",
      "---Fold 1\tAUROC:\t0.3519\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4159\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.6709\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6340\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4333\tEpochs:\t0\n",
      "------Run 17\n",
      "---Fold 1\tAUROC:\t0.6254\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5076\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.3637\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.6516\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3824\tEpochs:\t0\n",
      "------Run 18\n",
      "---Fold 1\tAUROC:\t0.5783\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4981\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5795\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5946\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.6532\tEpochs:\t0\n",
      "------Run 19\n",
      "---Fold 1\tAUROC:\t0.5276\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4184\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5285\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4724\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5583\tEpochs:\t0\n",
      "------Run 20\n",
      "---Fold 1\tAUROC:\t0.5722\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4551\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4936\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3171\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3232\tEpochs:\t0\n",
      "---------GABAergic SST interneuron\n",
      "------Run 1\n",
      "---Fold 1\tAUROC:\t0.5625\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5694\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5096\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4132\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4597\tEpochs:\t0\n",
      "------Run 2\n",
      "---Fold 1\tAUROC:\t0.6305\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6617\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5326\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.7556\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.6250\tEpochs:\t0\n",
      "------Run 3\n",
      "---Fold 1\tAUROC:\t0.4516\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5048\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5504\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.2697\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.3845\tEpochs:\t0\n",
      "------Run 4\n",
      "---Fold 1\tAUROC:\t0.6235\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.3469\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4017\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4226\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5643\tEpochs:\t0\n",
      "------Run 5\n",
      "---Fold 1\tAUROC:\t0.5450\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4807\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5876\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5793\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4604\tEpochs:\t0\n",
      "------Run 6\n",
      "---Fold 1\tAUROC:\t0.4897\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5164\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5993\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5042\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.5198\tEpochs:\t0\n",
      "------Run 7\n",
      "---Fold 1\tAUROC:\t0.5753\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6821\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.5818\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.4416\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.7107\tEpochs:\t0\n",
      "------Run 8\n",
      "---Fold 1\tAUROC:\t0.5660\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.4909\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.3605\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3923\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.4909\tEpochs:\t0\n",
      "------Run 9\n",
      "---Fold 1\tAUROC:\t0.4357\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.6087\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4164\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.5686\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.7171\tEpochs:\t0\n",
      "------Run 10\n",
      "---Fold 1\tAUROC:\t0.7660\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.2141\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.6164\tEpochs:\t0\n",
      "---Fold 4\tAUROC:\t0.3487\tEpochs:\t0\n",
      "---Fold 5\tAUROC:\t0.6839\tEpochs:\t0\n",
      "------Run 11\n",
      "---Fold 1\tAUROC:\t0.5414\tEpochs:\t0\n",
      "---Fold 2\tAUROC:\t0.5045\tEpochs:\t0\n",
      "---Fold 3\tAUROC:\t0.4137\tEpochs:\t0\n",
      "---Fold 4\t"
     ]
    }
   ],
   "source": [
    "auroc_list = []\n",
    "ad_dict = defaultdict(lambda: np.zeros(3))\n",
    "for cell_fname in cell_fnames:\n",
    "    cell_type = cell_fname.split('.')[0]\n",
    "    print(f'---------{cell_type}')\n",
    "\n",
    "    auroc_list.append([])\n",
    "    for run in range(runs):\n",
    "        print(f'------Run {run+1}')\n",
    "        \n",
    "        auroc_list[-1].append([])\n",
    "        for fold in range(folds):\n",
    "            print(f'---Fold {fold+1}', end='\\t')\n",
    "            \n",
    "            ### Generate graph\n",
    "            tg_genes = get_data(cell_fname, directed=directed)\n",
    "            reg_threshold = filter_elist(percentile)\n",
    "\n",
    "            ### Read graph\n",
    "            dim, num_walks, walk_length = dim_list[run], num_walks_list[run], walk_length_list[run]\n",
    "            dropout, lr, gamma = dropout_list[run], lr_list[run], gamma_list[run]\n",
    "            genes, labels, emb_pp = get_embeddings_from_elist(model_dir, cell_type, tg_genes, dim, num_walks, walk_length, percentile, run)\n",
    "                                        \n",
    "            ### Make dataset\n",
    "            dataset = generate_dataset(genes, labels, emb_pp, fold, folds, run)\n",
    "\n",
    "            ### Train model\n",
    "            model, end_epoch = generate_model(model_class, dataset, model_dir, model_str, cell_type, dim, num_walks, walk_length, dropout, lr, gamma, percentile, fold, folds, run, return_epoch=True)\n",
    "            \n",
    "            ### Perform predictions\n",
    "            auroc, pred_raw = evaluate_predictions(model, dataset, labels)\n",
    "            auroc_list[-1][-1].append(auroc)\n",
    "            # for i, g in enumerate(genes):\n",
    "            #     if (dataset.unk_mask[i] or dataset.val_mask[i]) and auroc > .5:\n",
    "            #         ad_dict[g] += np.array([auroc**2 * np.exp(float(pred_raw[i, 1])), auroc**2, 1])\n",
    "            \n",
    "            ### CLI\n",
    "            print(f'AUROC:\\t{auroc:.4f}', end='\\t')\n",
    "            print(f'Epochs:\\t{end_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e168dcd-543f-4d5d-87df-55ed17cd848e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save performance\n",
    "np.save(f'{results_dir}/auroc-{runs}-{folds}.npy', auroc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053578b6-d316-4e71-8a00-8aad58dae13b",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472d5dc-01fb-4c32-82b5-71ce9365b2bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load performances\n",
    "diseases = [\n",
    "    d for d in np.intersect1d(os.listdir(get_dirs('')[0]), os.listdir(get_dirs('')[1]))\n",
    "    if np.array([bad_text not in d for bad_text in ('old', 'enrichment', 'ipynb')]).all()]\n",
    "# diseases.sort(key=lambda d: ('-' in d))\n",
    "auroc_lists = [np.load(f'{get_dirs(d)[1]}/auroc-{runs}-{folds}.npy') for d in diseases]\n",
    "\n",
    "# Convert to pandas df\n",
    "df = pd.DataFrame(data={\n",
    "    'disease': np.concatenate([\n",
    "        folds*[d]\n",
    "        for d in diseases\n",
    "        for cts in [[s.split('.')[0] for s in os.listdir(f'./data/psychAD_merged_GRN_0.2_0.2/{d.split(\"-\")[0]}') if s[0] != '_']]\n",
    "        for ct in cts\n",
    "    ]),\n",
    "    'cell_type': np.concatenate([\n",
    "        folds*[ct]\n",
    "        for d in diseases\n",
    "        for cts in [[s.split('.')[0] for s in os.listdir(f'./data/psychAD_merged_GRN_0.2_0.2/{d.split(\"-\")[0]}') if s[0] != '_']]\n",
    "        for ct in cts\n",
    "    ]),\n",
    "    'fold': np.concatenate([\n",
    "        list(range(folds))\n",
    "        for d in diseases\n",
    "        for cts in [[s.split('.')[0] for s in os.listdir(f'./data/psychAD_merged_GRN_0.2_0.2/{d.split(\"-\")[0]}') if s[0] != '_']]\n",
    "        for ct in cts\n",
    "    ]),\n",
    "    'auroc': np.concatenate([np.concatenate(al[list(range(al.shape[0])), np.array(al).mean(axis=-1).argmax(axis=-1), :]) for al in auroc_lists]),\n",
    "}).sort_values(['cell_type', 'disease', 'fold'])  # Sorting required for patches with missing runs\n",
    "# Cherry-pick\n",
    "# df = df.iloc[[e not in np.array(cell_types)[[4, 7, 9, 10]] for e in df['cell_type']]]  # Remove cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028b3a1a-3272-482b-8b5c-1d143c596fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Style\n",
    "sns.set_palette('husl', len(diseases))\n",
    "style = {\n",
    "    'boxprops': {'edgecolor': None},\n",
    "    'medianprops': {'color': 'red', 'linewidth': 1},\n",
    "    'whiskerprops': {'color': 'black', 'linewidth': 1},\n",
    "    # 'capprops': {'alpha': 0},\n",
    "}\n",
    "\n",
    "# Create Figure\n",
    "fig, axs = plt.subplots(1, 1, figsize=(8, 4+2*len(diseases)), sharey=True)\n",
    "axs = [axs]\n",
    "\n",
    "# Barplot\n",
    "sns.boxplot(ax=axs[0], data=df, x='auroc', y='cell_type', hue='disease', **style)\n",
    "sns.move_legend(axs[0], 'upper right')\n",
    "sns.despine(ax=axs[0], left=True, bottom=True)\n",
    "\n",
    "# Labels\n",
    "axs[0].set_xlabel('AUROC')\n",
    "axs[0].set_ylabel('Cell Type')\n",
    "\n",
    "# Markers\n",
    "axs[0].axvline(x=.5, color='black', linestyle='--', linewidth=.5)\n",
    "axs[0].set_xlim([.4, 1. if np.max(df['auroc']) > .8 else .8])\n",
    "\n",
    "# Fade out alt runs\n",
    "box_patches = [patch for patch in axs[0].patches if type(patch) == mpl.patches.PathPatch]\n",
    "lines_per_boxplot = len(axs[0].lines) // len(box_patches)\n",
    "for i, patch in enumerate(box_patches):\n",
    "    # disease = diseases[i % len(diseases)]\n",
    "    disease = df.sort_values(['cell_type', 'disease']).iloc[::folds].iloc[i]['disease']\n",
    "    if '-' in disease:\n",
    "        # Change patch\n",
    "        patch.set_alpha(.2)\n",
    "        \n",
    "        # Change lines\n",
    "        for line in axs[0].lines[i * lines_per_boxplot: (i + 1) * lines_per_boxplot]:\n",
    "            line.set_alpha(.2)\n",
    "            \n",
    "# Save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{get_dirs(\"\")[1][:-1]}/fig_performance_box-{runs}-{folds}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e29a7cb-b274-4847-ae64-dd4c852a41be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Figure\n",
    "fig, axs = plt.subplots(1, 1, figsize=(2*len(diseases), len(np.unique(df['cell_type']))))\n",
    "axs = [axs]\n",
    "\n",
    "# Plot\n",
    "df_averages = (\n",
    "    df\n",
    "    .groupby(['cell_type', 'disease'])\n",
    "    .mean()\n",
    "    .drop(columns='fold')\n",
    "    .reset_index()\n",
    "    .pivot(index='cell_type', columns='disease', values='auroc')\n",
    ")\n",
    "ax = sns.heatmap(df_averages, vmin=.4, cmap='mako')\n",
    "\n",
    "# Highlight max per row (https://stackoverflow.com/questions/62696868/highlighting-maximum-value-in-a-column-on-a-seaborn-heatmap)\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "row_max = df_averages.idxmax(axis=1)\n",
    "\n",
    "for row, index in enumerate(df_averages.index):\n",
    "    positions = np.argsort(np.nan_to_num(np.array(df_averages.iloc[row])))[::-1][:2]\n",
    "    # position = df_averages.columns.get_loc(row_max[index])\n",
    "    for position in positions:\n",
    "        # ax.add_patch(Rectangle((position, row), 1, 1, fill=False, edgecolor='#FF0000', lw=2))\n",
    "        ax.add_patch(Circle((position+.5, row+.5), radius=1/32, color='#FF0000', lw=2))\n",
    "\n",
    "# Save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{get_dirs(\"\")[1][:-1]}/fig_performance_heat-{runs}-{folds}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8d1fb-d33a-4846-ad66-9b334651286c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "auroc_list = np.load(f'{results_dir}/auroc-{runs}-{folds}.npy')\n",
    "\n",
    "# Predict per cell type\n",
    "predictions = []\n",
    "for i, (cell_type, cell_fname) in enumerate(zip(cell_types, cell_fnames)):\n",
    "    print(f'Running {cell_type} predictions', end='\\t')\n",
    "    # Get best avg auroc for cell type\n",
    "    run = np.nanmean(auroc_list[i], axis=-1).argmax()\n",
    "    # Print hparams\n",
    "    print('(', end='')\n",
    "    for j, (hp_name, hp_val) in enumerate(zip(*np.loadtxt(f'{model_dir}/{model_str}-{cell_type}-{run}.txt', dtype=str))):\n",
    "        if j == 0:\n",
    "            print(f'{hp_name}: {hp_val}', end='')\n",
    "        else:\n",
    "            print(f', {hp_name}: {hp_val}', end='')\n",
    "    print(')')\n",
    "    \n",
    "    # Get validation predictions from each fold (TODO: Train on all data, one prediction)\n",
    "    for fold in range(folds):\n",
    "        # Predict\n",
    "        tg_genes = get_data(cell_fname, directed=directed)\n",
    "        reg_threshold = filter_elist(percentile)\n",
    "        dim, num_walks, walk_length = dim_list[run], num_walks_list[run], walk_length_list[run]\n",
    "        dropout, lr, gamma = dropout_list[run], lr_list[run], gamma_list[run]\n",
    "        genes, labels, emb_pp = get_embeddings_from_elist(model_dir, cell_type, tg_genes, dim, num_walks, walk_length, percentile, run)\n",
    "        dataset = generate_dataset(genes, labels, emb_pp, fold, folds, run)\n",
    "        model = generate_model(model_class, dataset, model_dir, model_str, cell_type, dim, num_walks, walk_length, dropout, lr, gamma, percentile, fold, folds, run)\n",
    "        auroc, pred_raw = evaluate_predictions(model, dataset, labels)\n",
    "        \n",
    "        # Record predictions\n",
    "        if fold == 0:\n",
    "            predictions_cell = np.zeros_like(pred_raw[:, 1])\n",
    "        assert np.sum(np.abs(predictions_cell[dataset.val_mask])) == 0\n",
    "        predictions_cell[dataset.val_mask] += pred_raw[dataset.val_mask][:, 1].numpy()\n",
    "        \n",
    "    # Format predictions\n",
    "    predictions_cell = np.array([[g, float(p)] for g, p in zip(genes, pred_raw[:, 1])])\n",
    "    predictions_cell = predictions_cell[np.argsort(predictions_cell[:, 1].astype(float))[::-1]]\n",
    "        \n",
    "    # Save predictions\n",
    "    fname = f'{results_dir}/{model_str}-{cell_type}-{runs}-{folds}-Predictions.txt'\n",
    "    np.savetxt(fname, predictions_cell, fmt='%s %s')\n",
    "        \n",
    "    predictions.append(predictions_cell)\n",
    "    \n",
    "# Concatenate\n",
    "# np.array(predictions)  # Sometimes ragged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70142d-a9dd-45f9-8012-2e7167e5e423",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get best cell type\n",
    "best_cell = (\n",
    "    np.nanmean(\n",
    "        auroc_list,\n",
    "        axis=-1,\n",
    "    )  # Average fold\n",
    "    .max(axis=-1)  # Max run\n",
    "    .argmax()  # Best cell idx\n",
    ")\n",
    "\n",
    "print(f'{cell_types[best_cell]} ({np.nanmean(auroc_list[best_cell], axis=-1).max():.3f}):')\n",
    "for g in predictions[best_cell][:100, 0]:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bebb5f4-f643-44cf-80b8-3706f0693715",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc8be0-54ee-4206-8bdc-d37fef8aa2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set colors\n",
    "sns.set_palette('husl', 3)\n",
    "\n",
    "# Maps\n",
    "name_map = {'pos': 'Disease', 'neg': 'Not Disease', 'unk': 'Unknown'}\n",
    "color_map = {'pos': np.array((1, .2, .2)), 'neg': np.array((.2, .2, 1)), 'unk': np.array((0, 0, 0))}\n",
    "z_map = {'pos': 2, 'neg': 1, 'unk': 0}\n",
    "s_map = {'pos': 10., 'neg': 1., 'unk': .5}\n",
    "\n",
    "# Translation\n",
    "trans = {'pos': 1, 'neg': 0, 'unk': 2}\n",
    "trans_inv = {v: k for k, v in trans.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc909b5-91c0-453c-bfb3-c45fe076b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Legend\n",
    "legend = [\n",
    "    Line2D([], [], color=(1, 1, 1, 0), markerfacecolor=color_map[l], marker='o', markersize=10)\n",
    "    for l in name_map]\n",
    "legend_names = [name_map[l] for l in name_map]\n",
    "\n",
    "# Plot legend\n",
    "fig, ax = plt.subplots()\n",
    "legend = ax.legend(legend, legend_names, loc='center', frameon=False, ncol=len(legend)//1)\n",
    "legend.figure.canvas.draw()\n",
    "bbox = legend.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{results_dir}/fig_legend.png', bbox_inches=bbox, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a5f4c-c57e-4749-b6a6-f78a46db6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display( Image(filename=f'{results_dir}/fig_legend.png', width=800) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82662834-b802-4efe-8900-895541c42b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get best model\n",
    "auroc_list = np.load(f'{results_dir}/auroc-{runs}-{folds}.npy')\n",
    "ct, run, fold = np.unravel_index(np.nanargmax(auroc_list), auroc_list.shape)\n",
    "cell_type, cell_fname = cell_types[ct], cell_fnames[ct]\n",
    "\n",
    "### Load best model\n",
    "tg_genes = get_data(cell_fname, directed=directed)\n",
    "reg_threshold = filter_elist(percentile)\n",
    "dim, num_walks, walk_length = dim_list[run], num_walks_list[run], walk_length_list[run]\n",
    "dropout, lr, gamma = dropout_list[run], lr_list[run], gamma_list[run]\n",
    "genes, labels, emb_pp = get_embeddings_from_elist(model_dir, cell_type, tg_genes, dim, num_walks, walk_length, percentile, run)\n",
    "dataset = generate_dataset(genes, labels, emb_pp, fold, folds, run)\n",
    "model = generate_model(model_class, dataset, model_dir, model_str, cell_type, dim, num_walks, walk_length, dropout, lr, gamma, percentile, fold, folds, run)\n",
    "auroc, pred_raw = evaluate_predictions(model, dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c5900-1680-402f-84b0-666bd9b77a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# submask = torch.tensor((np.random.rand(dataset.x.shape[0]) > .7), dtype=bool)\n",
    "submask = dataset.val_mask\n",
    "G = tg.utils.to_networkx(dataset.subgraph(np.argwhere(submask).flatten()), node_attrs=['x'], edge_attrs=['edge_weight'], to_undirected=not directed)\n",
    "edge_color = [(0, 0, 0, .1*G[u][v]['edge_weight'] / float(dataset.subgraph(np.argwhere(submask).flatten()).edge_weight.max())) for u, v in G.edges]\n",
    "pos = nx.spring_layout(G, weight='edge_weight', k=.5)\n",
    "\n",
    "# Original Data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "node_color = [color_map[trans_inv[int(v)]] for v in dataset.y[submask]]\n",
    "nx.draw(\n",
    "    G,\n",
    "    node_color=node_color,\n",
    "    edge_color=edge_color,\n",
    "    node_size=10,\n",
    "    pos=pos,\n",
    ")\n",
    "plt.title('Gene Coregulation')\n",
    "plt.savefig(f'{results_dir}/fig_data-{runs}-{folds}.png', dpi=300)\n",
    "\n",
    "# Computed Data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "# pred = model(dataset).detach().argmax(dim=1)\n",
    "threshold = pred_raw[dataset.train_mask, 1].flatten().quantile(1 - (sum(labels=='pos') / (sum(labels=='pos') + sum(labels=='neg'))))\n",
    "pred = 1*(model(dataset).detach()[:, 1] > threshold)\n",
    "# Show known\n",
    "# node_color = [color_map[trans_inv[int(v)]] if v != 2 else color_map[trans_inv[int(w)]] for v, w in zip(dataset.y[submask], pred[submask])]\n",
    "# Do not show known\n",
    "# node_color = [color_map[trans_inv[int(v)]] for v in pred[submask]]\n",
    "# Show spectrum\n",
    "strong_range = np.std(pred_raw[submask, 1].exp().numpy())\n",
    "center = np.percentile(pred_raw[submask, 1].exp().numpy(), 90)\n",
    "min_range, max_range = center - strong_range, center + strong_range\n",
    "node_color = [\n",
    "    np.array(\n",
    "        (1-((max(min(v[1], max_range), min_range) - min_range)/(2*strong_range)))*color_map['neg']\n",
    "        + ((max(min(v[1], max_range), min_range) - min_range)/(2*strong_range))*color_map['pos']\n",
    "    )\n",
    "        for v in pred_raw[submask].exp().numpy()]\n",
    "node_color = [[max(min(cv, 1), 0) for cv in c] for c in node_color]\n",
    "nx.draw(\n",
    "    G,\n",
    "    node_color=node_color,\n",
    "    edge_color=edge_color,\n",
    "    node_size=10,\n",
    "    pos=pos,\n",
    ")\n",
    "plt.title('Predicted Disease')\n",
    "plt.savefig(f'{results_dir}/fig_prediction-{runs}-{folds}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7913b-b286-431e-b559-e9bd0394a8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_plus",
   "language": "python",
   "name": "gnn_plus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
